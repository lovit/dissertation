%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Prudent space correction and influence noise level of training data}

한국어는 띄어쓰기 기준으로 어절이 구분된다.
그러나 어절 사이에 띄어쓰기가 존재하지 않더라도 가독이 어렵지 않은 경우들이 있기 때문에 인접한 어절을 붙여쓰는 경우가 존재한다.
표 \ref{tab:space_example} 의 문장 1 은 띄어쓰기 오류가 없는 경우지만, 문장 2 처럼 두 어절을 붙여도 가독에 큰 어려움이 없다.
그렇기 때문에 띄어쓰기 입력이 번거로운 모바일 기기로부터 입력된 한국어 텍스트에는 띄어쓰기 오류가 포함될 가능성이 높다.
이와 같은 오류는 품사 판별 과정의 계산 비용과 모호성을 증가시키기 때문에 오류를 제거할 필요가 있다.

\begin{table}[H]
\centering
\caption{띄어쓰기 오류가 포함된 문장 예시}
\label{tab:space_example}
\begin{tabular}{|l|}
\hline
\begin{tabular}[c]{@{}l@{}}(문장 1) : 띄어쓰기 오류를 교정합니다\\ (문장 2) : 띄어쓰기오류를 교정합니다\\ (문장 3) : 띄어쓰 기오 류를교 정합니 다\end{tabular} \\ \hline
\end{tabular}
\end{table}

하지만 표 \ref{tab:space_example} 의 문장 3 처럼 어절 내 붙여써야 하는 부분을 띄어쓰는 경우에는 가독이 어렵다.
즉 한국어 띄어쓰기 오류는 "본래 띄어써야 하는 어절 간의 경계를 붙여쓴 경우"로 한정할 수 있고, 띄어쓰기 오류 교정은 "붙여쓴 글자 사이에 어절 경계가 존재할 경우 이를 띄어쓰는 것"으로 정의할 수 있다.

그리고 띄어쓰기 교정은 이후 품사 판별과 같은 다른 자연어처리 과업의 비용과 모호성을 줄이는 것이 목적이므로, 교정이 보수적으로 이뤄저야 한다.
문장 3 처럼 붙여써야 하는 부분이 띄어진 경우 이를 단어로 인식하는 것은 매우 어려우며, 한국어 품사 판별기와 형태소 분석기는 띄어쓰기로 구분된 두 어절은 서로 다른 단어로 가정하는 경우가 많다.

한국어 띄어쓰기 교정 문제는 글자 시퀀스가 입력되었을 때 각 글자에 이진 태그 (띄어쓴다, 붙여쓴다)를 부여하는 시퀀스 레이블링 작업으로 정의할 수 있다.
이를 위하여 부분 글자열을 벡터의 변수로 이용하는 CRF 와 같은 시퀀스 레이블링 알고리즘들이 이용될 수 있다 \citep{lee2002automatic, lee2007automatic, shim2011crf, lee2013automatic, lee2013joint, Lee2017adatadriven, hong2007korean, kang2006category}.

하지만 글자 수준의 시퀀스 레이블링 알고리즘을 이용하여 띄어쓰기 교정기를 학습할 때에는 다음의 어려움이 발생한다.
첫째, 띄어쓰기 오류 교정을 위해서는 띄어쓰기 오류가 없는 학습데이터가 필요하다.
하지만 학습 데이터는 띄어쓰기 교정을 할 문서 집합의 도메인을 포함하여야 한다.
시퀀스 레이블링 모델은 학습 데이터에 존재하는 부분 글자 시퀀스를 이용하여 적절한 띄어쓰기 태그를 부여한다.
만약 학습 데이터에 존재하지 않는 단어열이 입력될 경우에는 이를 제대로 처리하지 못한다.
뉴스 텍스트의 단어 분포는 일상 대화나 영화평 텍스트의 단어 분포를 포함하지 못하며, 일상 대화나 영화평 텍스트의 단어 분포를 포함하는 데이터를 구축해야 한다.
단어 분포 포함되는 데이터를 수집했더라도 그 데이터의 띄어쓰기 오류가 적어야 학습에 이용할 수 있다.

둘째, 어절의 끝부분이 포함된 단어나 복합명사는 잘못된 띄어쓰기 교정이 될 가능성이 높다.
이는 CRF 와 같은 알고리즘이 문맥에 상관없이 가능한 모든 부분 글자열을 변수로 이용하기 때문이다.
"이다음에보자" 라는 문장에서 두번째 글자 "다" 이후 띄어야 할지 결정할 때 CRF 는 "X[-1:0] = 이다" 를 변수로 이용한다.
"-이다"는 용언의 종결형으로 이용되는 경우가 많기 때문에 이를 변수로 이용하면 "이다 음에보자" 처럼 잘못된 품사 태깅을 할 가능성이 있다.
"X[-1:3] = 이다음에보" 와 같은 다른 변수에 의하여 띄어쓰기를 하지 않을 가능성도 있지만, "이다음에"라는 문맥에서 "X[-1:0] = 이다"를 이용하지 않을 수 있다면 안정적인 띄어쓰기 교정의 가능성이 높아진다.
또한 데이터에 따라 CRF 의 잠재 함수 (potential function) 에 의하여 생성되는 변수 공간이 linear inseparable 일 수 있으며, 이때에는 잘못된 띄어쓰기 교정을 할 가능성이 높다.
또한 softmax regression 형식인 CRF 는 확률이 가장 높은 품사열을 출력하기 때문에 각 글자 별 한계값 (threshold) 을 부여하기 어렵다.

셋째, gradient descent 기반 방법들은 모델의 패러매터가 많을수록 계산 비용이 증가한다.
변수로 이용하는 부분 글자열의 길이가 길어질수록 CRF 의 잠재 함수에 의하여 생상되는 변수 공간의 크기는 기하급수적으로 증가한다.
학습 데이터에 존재하는 단어의 종류가 증가하여도 생성되는 변수의 공간은 증가한다.
그렇기 때문에 다양한 단어들이 존재하는 대량의 텍스트 데이터로부터 모델을 학습하기 위해서는 많은 계산 비용이 필요하다.

이번 3 장에서는 보수적인 띄어쓰기 교정을 위한 휴리스틱 띄어쓰기 교정 알고리즘을 제안하며, 학습 데이터의 구축을 위한 경험적 방법 및 학습 데이터의 띄어쓰기 오류 수준에 따른 오류 교정의 영향을 분석한다.
제안된 알고리즘은 CRF 보다 보수적인 띄어쓰기 교정 성능을 보였으며, 사용자가 보수적인 수준을 조절하거나 사용자의 경험적 지식을 모델에 부여할 수 있다.
또한 CRF 나 RNN 처럼 gradient descent 방법을 이용하지 않고, 부분 글자 시퀀스의 빈도수를 계산하는 것 만으로 학습 하기 때문에 대량의 데이터에 대하여 빠른 학습이 가능하다.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proposed method}

위의 관찰을 바탕으로 문맥에 따라 변수를 선택적으로 이용하는 알고리즘을 제안한다.
이를 위하여 부분 글자열을 변수로 이용하는 경우, 변수의 종류를 세 가지로 분류한다.
글자열을 $X$ 라 할 때, 현재 시점을 기준으로 좌측에 등장한 부분 글자열 $X[-k:0]$ 을 $L$ 로, 우측에 등장한 부분 글자열 $X[0:k]$ 을 $R$ 로, 좌측과 우측의 글자를 모두 이용하는 부분 글자열 $X[-k:l]$ 을 $C$ 로 명명한다.
앞선 문장, "이다음에보자"에서 "X[-1:0] = 이다" 는 $L$ 에 해당하며, "X[-1:2] = 이다음에" 는 $C$ 에 해당한다.
$L$ 은 앞의 문맥만을, $R$ 은 뒤의 문맥만을, $C$ 는 양쪽의 문맥을 모두 고려하는 변수이다.

제안하는 알고리즘은 빈도수를 기반으로 각 부분 글자열 변수에 띄어쓰기 계수를 부여한다.
학습 데이터에서 부분 글자열의 한 시점에 띄어쓰기가 이뤄진 빈도수를 $n_p$, 붙여쓰기가 이뤄진 빈도수를 $n_n$ 이라 할 때, 한 변수의 띄어쓰기 계수는 식 \ref{eq:space_coefficient} 로 정의한다.

\begin{equation}
  \label{eq:space_coefficient}
  score(X[-k:l]) = \frac{n_p - n_n}{n_p + n_n}
\end{equation}

예를 들어 "X[-1:2] = 이다음에" 의 부분 글자열에서 '다' 다음에 띄어쓴 경우가 5 번, 붙여쓴 경우가 95 번이라면 이는 식 \ref{eq:space_coefficient} 에 따라 -0.9 의 계수가 학습된다.
모든 경우에 붙여쓰기가 되었다면 계수는 -1 이며, 모든 경우에 띄어쓰기가 되었다면 계수는 1 이 된다.
각 종류의 변수 별 띄어쓰기 점수는 해당 종류의 모든 변수의 $n_p, n_n$ 의 합으로 정의한다.

앞선 관찰에서 $L$ 이나 $R$ 변수만을 이용하면 잘못된 띄어쓰기 의사결정을 할 수 있음을 확인하였다.
학습 데이터에 변수가 충분히 등장하였다면 좌, 우의 많은 글자를 이용하는 $C$ 종류의 변수를 이용하면 정확한 띄어쓰기 태깅을 할 수 있지만, $C$ 종류의 변수가 충분히 등장하지 않을 때에는 $L$ 과 $R$ 을 이용해야 한다.
만약 $L, C, R$ 세 종류 변수의 띄어쓰기 점수가 모두 $(0.9, 0.8, 0.85)$ 처럼 1 에 가까운 양수라면 해당 글자는 띄어쓰기를 해야 할 가능성이 높다.
만약 $L, R$ 의 변수가 존재하지 않은데, $C$ 의 계수가 1 에 가까운 값을 계수를 지닌다면 띄어쓰기를 해야 할 가능성이 높다.
하지만 정확한 문맥을 표현하는 $C$ 가 존재하지 않고, $L$ 과 $R$ 이 $(-0.9, 0, 0.8)$ 처럼 서로 다른 부호의 띄어쓰기 계수를 지닌다면, 서로 불확실한 정보를 지닌 상황이기 떄문에 잘못된 띄어쓰기를 할 가능성이 있다.
이처럼 불확실한 상황에서는 태깅을 하지 않아야 잘못된 띄어쓰기 교정을 방지할 수 있다.
만약 $(0.9, 0, 0.8)$ 처럼 $L, R$ 이 같은 부호의 계수를 지닐 때에만 태깅을 수행하는 것이 적합하다.

위의 관찰을 바탕으로 다음과 같은 띄어쓰기 태깅 규칙을 부여할 수 있다.

\begin{enumerate}[noitemsep]
  \item 세 종류 변수  $L, C, R$ 의 빈도수가 0 보다 크고, 같은 부호의 계수를 지니면 L, C, R 계수의 평균을 띄어쓰기 태깅 점수로 이용
  \item $L, R$ 의 빈도수가 0 이지만 $C$ 의 빈도수가 0 이상이면 C 의 점수를 띄어쓰기 점수로 이용
  \item $L$ 이나  $R$ 의 빈도수가 0보다 크고 $C$ 와 같은 부호의 계수를 지니면 빈도수가 0 보다 큰 계수의 평균을 띄어쓰기 점수로 이용
  \item $C$ 의 빈도수가 0 일 때, $L$ 과 $R$ 의 계수가 같으면 $L, R$ 계수의 평균을 띄어쓰기 태깅 점수로 이용
  \item 그 외는 띄어쓰기 태깅을 수행하지 않음 (단, 첫글자는 제외)
\end{enumerate}





\vspace{3cm}
\textit{모델 설명 추가}
\vspace{3cm}



\subsection{Evaluation}

제안하는 모델의 성능을 평가하기 위하여 띄어쓰기 오류가 거의 존재하지 않는 뉴스 기사로부터 수집한 223,357 건의 문장을 이용하였다.
띄어쓰기 교정 모델의 학습 데이터에 띄어쓰기 오류가 포함된 상황을 만들기 위하여 문장 내 띄어쓰기에 대하여 1\% 부터 50\% 의 비율로 띄어쓰기를 제거하여 띄어쓰기 오류가 존재하는 학습 데이터를 생성하였다.

비교 모델로 동일한 종류의 부분 글자열 변수를 이용하는 CRF 기반 모델을 이용하였다.
두 모델 모두 길이가 3 \~ 7 사이인 부분 어절을 변수로 이용하였으며, 최소 빈도수 5 번 이상 등장한 변수만 이용하였다.
CRF 의 학습은 python-crfsuite 를 이용하였으며, 변수 선택이 되지 않도록 L1 regularization 은 이용하지 않았다.

표 \ref{tab:remain_noise_proposed} 은 제안하는 모델을 이용하여 띄어쓰기 오류를 교정한 뒤 남은 오류의 비율이다.
띄어쓰기 오류가 5\% 포함된 데이터로 모델을 학습하여 띄어쓰기 오류가 30\% 인 데이터의 오류를 교정하면 24.533\% 를 교정하고 5.467\% 가 남았다는 의미이다.

표 \ref{tab:remain_noise_crf} 은 CRF 기반 모델을 이용하여 오류를 교정한 뒤 남은 오류의 비율이다.
5\% 의 오류가 포함된 데이터로 모델을 학습한 뒤, 30\% 의 오류가 포함된 데이터를 교정하면 5.416\% 의 오류만 남았음을 확인할 수 있다.
제안된 모델은 CRF 기반 모델보다 더 적은 양의 띄어쓰기 오류를 교정한다.

\begin{table}[H]
\centering
\label{tab:remain_noise_proposed}
\caption{Remained noise of proposed method [\%]}
\begin{tabular}{|c|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{remain noise}} & \multicolumn{10}{c|}{Test data noise level} \\ \cline{3-12} 
\multicolumn{2}{|c|}{} & 1 & 2 & 3 & 5 & 10 & 15 & 20 & 30 & 40 & 50 \\ \hline
\multirow{10}{*}{\begin{tabular}[c]{@{}c@{}}Train\\ data\\ noise\\ level\end{tabular}} & 1 & 0.203 & 0.341 & 0.52 & 0.854 & 1.731 & 2.581 & 3.424 & 5.125 & 6.807 & 8.475 \\ \cline{2-12} 
 & 2 & 0.175 & 0.41 & 0.527 & 0.866 & 1.753 & 2.615 & 3.47 & 5.197 & 6.901 & 8.591 \\ \cline{2-12} 
 & 3 & 0.177 & 0.351 & 0.638 & 0.88 & 1.785 & 2.665 & 3.534 & 5.294 & 7.028 & 8.75 \\ \cline{2-12} 
 & 5 & 0.183 & 0.363 & 0.554 & 1.097 & 1.844 & 2.752 & 3.649 & 5.467 & 7.259 & 9.027 \\ \cline{2-12} 
 & 10 & 0.203 & 0.4 & 0.61 & 1.009 & 2.508 & 3.044 & 4.033 & 6.039 & 8.02 & 9.978 \\ \cline{2-12} 
 & 15 & 0.231 & 0.454 & 0.692 & 1.144 & 2.308 & 4.323 & 4.572 & 6.843 & 9.089 & 11.314 \\ \cline{2-12} 
 & 20 & 0.269 & 0.534 & 0.81 & 1.341 & 2.701 & 4.041 & 6.805 & 8.024 & 10.656 & 13.27 \\ \cline{2-12} 
 & 30 & 0.433 & 0.861 & 1.312 & 2.166 & 4.351 & 6.513 & 8.67 & 16.217 & 17.277 & 21.554 \\ \cline{2-12} 
 & 40 & 0.798 & 1.581 & 2.391 & 3.969 & 7.945 & 11.927 & 15.908 & 23.861 & 34.821 & 39.839 \\ \cline{2-12} 
 & 50 & 0.896 & 1.777 & 2.691 & 4.465 & 8.921 & 13.413 & 17.88 & 26.829 & 35.773 & 46.123 \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\label{tab:remain_noise_crf}
\caption{Remained noise of CRF based model [\%]}
\begin{tabular}{|c|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{remain noise}} & \multicolumn{10}{c|}{Test data noise level} \\ \cline{3-12} 
\multicolumn{2}{|c|}{} & 1 & 2 & 3 & 5 & 10 & 15 & 20 & 30 & 40 & 50 \\ \hline
\multirow{10}{*}{\begin{tabular}[c]{@{}c@{}}Train\\ data\\ noise\\ level\end{tabular}} & 1 & 0.164 & 0.334 & 0.508 & 0.833 & 1.681 & 2.493 & 3.290 & 4.871 & 6.390 & 7.850 \\ \cline{2-12} 
 & 2 & 0.122 & 0.245 & 0.361 & 0.592 & 1.178 & 1.747 & 2.280 & 3.302 & 4.241 & 5.093 \\ \cline{2-12} 
 & 3 & 0.143 & 0.280 & 0.435 & 0.696 & 1.401 & 2.072 & 2.716 & 3.987 & 5.184 & 6.321 \\ \cline{2-12} 
 & 5 & 0.192 & 0.373 & 0.567 & 0.936 & 1.870 & 2.784 & 3.669 & 5.416 & 7.097 & 8.706 \\ \cline{2-12} 
 & 10 & 0.272 & 0.532 & 0.812 & 1.332 & 2.731 & 3.972 & 5.245 & 7.765 & 10.195 & 12.527 \\ \cline{2-12} 
 & 15 & 0.363 & 0.715 & 1.092 & 1.792 & 3.584 & 5.488 & 7.110 & 10.591 & 13.996 & 17.328 \\ \cline{2-12} 
 & 20 & 0.355 & 0.701 & 1.070 & 1.759 & 3.511 & 5.261 & 7.198 & 10.348 & 13.648 & 16.868 \\ \cline{2-12} 
 & 30 & 0.420 & 0.827 & 1.260 & 2.074 & 4.137 & 6.200 & 8.209 & 12.754 & 16.133 & 19.970 \\ \cline{2-12} 
 & 40 & 0.550 & 1.092 & 1.653 & 2.728 & 5.428 & 8.138 & 10.786 & 16.078 & 22.158 & 26.369 \\ \cline{2-12} 
 & 50 & 0.685 & 1.362 & 2.055 & 3.406 & 6.789 & 10.178 & 13.535 & 20.214 & 26.796 & 34.296 \\ \hline
\end{tabular}
\end{table}

그러나 표 \ref{tab:false_space_proposed} 과 표 \ref{tab:false_space_crf} 를 비교하면 동일 데이터로 학습하였을 경우, 더 적은 양의 잘못된 띄어쓰기 오류 교정을 하는 것을 확인할 수 있다.
표 \ref{tab:false_space_proposed} 에서 제안된 모델은 5\% 오류가 포함된 학습 데이터로 30\% 오류가 포함된 데이터의 오류를 교정할 때, 0.371\% 의 잘못된 교정을 수행하지만, CRF 기반 모델은 1.058\% 의 잘못된 교정을 수행한다.

\begin{table}[H]
\centering
\label{tab:false_space_proposed}
\caption{False space correction of proposed method [\%]}
\begin{tabular}{|c|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{remain noise}} & \multicolumn{10}{c|}{Test data noise level} \\ \cline{3-12} 
\multicolumn{2}{|c|}{} & 1 & 2 & 3 & 5 & 10 & 15 & 20 & 30 & 40 & 50 \\ \hline
\multirow{10}{*}{\begin{tabular}[c]{@{}c@{}}Train\\ data\\ noise\\ level\end{tabular}} & 1 & 0.406 & 0.407 & 0.408 & 0.410 & 0.414 & 0.418 & 0.422 & 0.431 & 0.439 & 0.449 \\ \cline{2-12} 
 & 2 & 0.394 & 0.394 & 0.396 & 0.397 & 0.402 & 0.406 & 0.409 & 0.418 & 0.426 & 0.435 \\ \cline{2-12} 
 & 3 & 0.380 & 0.381 & 0.381 & 0.383 & 0.388 & 0.392 & 0.395 & 0.403 & 0.411 & 0.420 \\ \cline{2-12} 
 & 5 & 0.350 & 0.350 & 0.351 & 0.351 & 0.356 & 0.360 & 0.363 & 0.371 & 0.378 & 0.387 \\ \cline{2-12} 
 & 10 & 0.284 & 0.284 & 0.285 & 0.286 & 0.288 & 0.292 & 0.295 & 0.302 & 0.309 & 0.316 \\ \cline{2-12} 
 & 15 & 0.223 & 0.223 & 0.224 & 0.225 & 0.228 & 0.227 & 0.233 & 0.239 & 0.244 & 0.250 \\ \cline{2-12} 
 & 20 & 0.177 & 0.177 & 0.178 & 0.179 & 0.181 & 0.183 & 0.180 & 0.190 & 0.194 & 0.199 \\ \cline{2-12} 
 & 30 & 0.084 & 0.084 & 0.084 & 0.084 & 0.085 & 0.086 & 0.087 & 0.081 & 0.089 & 0.091 \\ \cline{2-12} 
 & 40 & 0.028 & 0.028 & 0.028 & 0.028 & 0.029 & 0.029 & 0.029 & 0.028 & 0.024 & 0.030 \\ \cline{2-12} 
 & 50 & 0.015 & 0.015 & 0.015 & 0.015 & 0.015 & 0.015 & 0.015 & 0.015 & 0.015 & 0.012 \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\label{tab:false_space_crf}
\caption{False space correction of CRF based model [\%]}
\begin{tabular}{|c|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{remain noise}} & \multicolumn{10}{c|}{Test data noise level} \\ \cline{3-12} 
\multicolumn{2}{|c|}{} & 1 & 2 & 3 & 5 & 10 & 15 & 20 & 30 & 40 & 50 \\ \hline
\multirow{10}{*}{\begin{tabular}[c]{@{}c@{}}Train\\ data\\ noise\\ level\end{tabular}} & 1 & 1.149 & 1.154 & 1.159 & 1.168 & 1.192 & 1.213 & 1.238 & 1.285 & 1.331 & 1.377 \\ \cline{2-12} 
 & 2 & 1.726 & 1.735 & 1.745 & 1.764 & 1.815 & 1.863 & 1.916 & 2.017 & 2.117 & 2.224 \\ \cline{2-12} 
 & 3 & 1.278 & 1.284 & 1.289 & 1.299 & 1.327 & 1.353 & 1.382 & 1.437 & 1.491 & 1.546 \\ \cline{2-12} 
 & 5 & 0.941 & 0.946 & 0.949 & 0.957 & 0.978 & 0.996 & 1.017 & 1.058 & 1.097 & 1.139 \\ \cline{2-12} 
 & 10 & 0.549 & 0.552 & 0.555 & 0.561 & 0.578 & 0.591 & 0.609 & 0.641 & 0.673 & 0.704 \\ \cline{2-12} 
 & 15 & 0.345 & 0.347 & 0.349 & 0.353 & 0.363 & 0.373 & 0.383 & 0.405 & 0.425 & 0.444 \\ \cline{2-12} 
 & 20 & 0.376 & 0.378 & 0.380 & 0.385 & 0.395 & 0.405 & 0.416 & 0.437 & 0.458 & 0.476 \\ \cline{2-12} 
 & 30 & 0.230 & 0.231 & 0.232 & 0.235 & 0.242 & 0.248 & 0.255 & 0.269 & 0.281 & 0.293 \\ \cline{2-12} 
 & 40 & 0.126 & 0.126 & 0.127 & 0.128 & 0.132 & 0.134 & 0.137 & 0.144 & 0.150 & 0.155 \\ \cline{2-12} 
 & 50 & 0.059 & 0.059 & 0.059 & 0.060 & 0.062 & 0.063 & 0.065 & 0.069 & 0.073 & 0.076 \\ \hline
\end{tabular}
\end{table}

표 \ref{tab:remain_noise_proposed} 와 \ref{tab:remain_noise_crf} 는 Recall 에 해당하며, 표 \ref{tab:false_space_proposed} 와 \ref{tab:false_space_crf} 는 Precision 에 해당하기 때문에 F1 score 를 계산할 수 있다.

1\% 부터 50\% 의 모든 오류 수준에 대한 F1 macro 는 제안하는 모델이 0.698, CRF 기반 모델이 0.693 을 보인다.
하지만 학습 데이터에서 띄어쓰기 오류가 심한 데이터는 간단한 규칙 기반으로 걸러낼 수 있으므로, 학습 데이터의 띄어쓰기 오류 수준을 최대 30\% 라고 가정한다면 제안하는 모델의 F1 macro 는 0.808, CRF 기반 모델은 0.731 이다.
즉 제안하는 띄어쓰기 교정 모델은 CRF 기반 모델보다 보수적으로 띄어쓰기를 교정하지만, 잘못된 띄어쓰기를 적게 수행하여 안정적인 교정 효과를 얻을 수 있다.

\subsection{Discussion}

모델을 적용할 문서 집합의 단어 분포를 잘 반영하려면 학습 데이터를 모델을 적용할 문서 집합에서 구축하여야 한다.
그러나 수작업으로 띄어쓰기 오류를 교정하여 학습 데이터를 만드는 것은 불가능한 일이다.
하지만 표 \ref{tab:remain_noise_proposed} 와 \ref{tab:remain_noise_crf} 로부터 학습 데이터에 일정 수준의 띄어쓰기 오류가 포함되어 있더라도 띄어쓰기 교정이 잘 이뤄짐을 확인할 수 있다.
띄어쓰기 없다면 한국어의 어절의 평균 길이는 약 3.4 로, 한 문장에서 띄어쓰기가 존재하는 비율이 0.29 라는 의미이다.
띄어쓰기 오류를 교정할 데이터에서 문장 길이 대비 띄어쓰기의 비율을 계산한 다음, 해당 비율이 특정 값 이상인 문장을 선택하면 평균 오류 수준이 특정 값 이상인 학습 데이터를 선택할 수 있다.
예를 들어 평균 오류 비율을 30\% 이하로 맞추기 위해서 각 문장의 띄어쓰기 비율이 $0.29 \times 0.7 = 0.203$ 이상인 문장들을 선택할 수 있다.
이와 같은 기준을 이용하여 상대적으로 오류가 적은 문장들을 선택한다면, 교정할 문서 집합의 단어 분포와 가장 일치하면서 오류가 적은 학습 데이터를 손쉽게 구축할 수 있다.

입력 문장에는 사용자에 의하여 작성된 일부의 띄어쓰기 정보가 포함되어 있다.
띄어쓰기 오류가 지나치게 많을 경우 가독성이 매우 떨어지기 때문에, 사람이 작성한 텍스트에는 구문 단위로 띄어쓰기가 일부 포함된 경우들이 많다.
이는 사람에 의하여 명확히 태깅된 띄어쓰기 태그이기 때문에 이 정보를 반드시 이용해야 한다.
이 정보를 이용하지 않는 경우는 입력된 문장의 모든 띄어쓰기를 제거한 뒤, 다시 띄어쓰기를 수행하는 것이다.
입력 데이터의 띄어쓰기 정보를 태그로 이용하는 경우의 효과를 확인하기 위하여 제안한 모델과 CRF 기반 모델을 각각 3, 10, 20\% 의 띄어쓰기 오류가 포함된 학습 데이터를 이용하여 모델을 학습한 뒤, 10\% 띄어쓰기 오류가 있는 데이터와 100\% 오류가 있는 데이터의 오류를 수정하였다.
표 \ref{tab:remain_noise_proposed} 과 \ref{tab:no_use_user_space_crf} 에서 두 모델 모두 입력 데이터의 띄어쓰기 정보를 이용하지 않으면 많은 양의 오류를 수정하지 못함을 확인할 수 있다.

\begin{table}[H]
\centering
\label{tab:no_use_user_space_proposed}
\caption{Remained noise when use no user space tag with proposed method [\%]}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{Remain noise (\%)} & With space (10 \% noise) & Without space \\ \hline
\multirow{3}{*}{Train data noise level} & 3 & 1.785 & 19.591 \\ \cline{2-4} 
 & 10 & 2.508 & 21.996 \\ \cline{2-4} 
 & 20 & 2.701 & 28.384 \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\label{tab:no_use_user_space_crf}
\caption{Remained noise when use no user space tag with CRF based model [\%]}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{Remain noise (\%)} & With space (10 \% noise) & Without space \\ \hline
\multirow{3}{*}{Train data noise level} & 3 & 1.401 & 11.116 \\ \cline{2-4} 
 & 10 & 2.731 & 23.241 \\ \cline{2-4} 
 & 20 & 3.511 & 32.052 \\ \hline
\end{tabular}
\end{table}

\subsection{Conclusion}

TODO
\vspace{3cm}