% Set parameters
% set font size
\documentclass[11pt]{article}

% set line height
\renewcommand{\baselinestretch}{2}

% line number
\usepackage{lineno}

% today
\renewcommand{\today}{}

% set margin
\usepackage{geometry}
\geometry{a4paper, left=15mm, right=15mm, top=20mm, bottom=20mm}

% for using Korean
\usepackage{kotex}

% for using multi-languages
\usepackage[english]{babel}

% for urls
\usepackage{hyperref}

% for equation
\usepackage{amsmath}

% for fixing figure position
\usepackage{float}

% for bibliography
\usepackage{apacite}
\usepackage[numbers]{natbib}

% for drawing table
\usepackage{array,multirow,graphicx,rotating,booktabs}
\usepackage[table,xcdraw]{xcolor}

% for tabularx
\usepackage{tabularx}
\newcolumntype{b}{X}
\newcolumntype{s}{>{\hsize=.5\hsize}X}
\renewcommand\arraystretch{0.8} \setlength\minrowclearance{0.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{Unsupervised Korean Natural Language Processing to Solve Out-of-Vocabulary and Dearth of Data}

\maketitle
\smallskip

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Journals}

\subsection{Accepted papers}

\begin{enumerate}
    \item "Representation learning for unsupervised heterogeneous multivariate time series segmentation and its application", \textbf{Hyunjoong Kim}, Han Kyul Kim, Misuk Kim, Jooseoung Park, Sungzoon Cho, Keyng Bin Im, and Chang Ryeol Ryu, Computers \& Industrial Engineering
    \item "Bag-of-Concepts: Comprehending Document Representation through Clustering Words in Distributed Representation", Han Kyul Kim,  \textbf{Hyunjoong Kim}, Sungzoon Cho, Neurocomputing. Volume 266, 29 November 2017, Pages 336-352
    \item "KR-WordRank: A Korean word extraction method based on WordRank and unsupervised learning",  \textbf{Hyunjoong Kim}, Sungzoon Cho and Pilsung Kang, 대한산업공학회지, 2014, Vol. 40(1): 18-33.
    \item "추천 시스템 기법 연구동향 분석", 손지은, 김성범,  \textbf{김현중}, 조성준, 대한산업공학회지, Apr 2015, Vol.41, No.2, pp.185-208.
    \item "Fast Parameterless Ballistic Launch Point Estimation based on k-NN Search", Soojin Kim,  \textbf{Hyunjoong Kim}, Sungzoon Cho, Defence Science Journal, Volume 64, No 1, January 2014, Pages 41-47. (SCIE)
\end{enumerate}

\subsection{Submitted papers}

\begin{enumerate}
    \item "Improving spherical k-means for document clustering: Fast initialization, sparse centroid projection, and efficient cluster labeling", \textbf{Hyunjoong Kim}, Han Kyul Kim, Sungzoon Cho, Expert System with Applications
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Chapters}

\begin{enumerate}
    \item Introduction
    \item Enhancing Korean Morphological Analysis with Word Extraction
    \item Building Named Entity Recognizer from Active Learning
    \item Keyword Extraction
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Chapters detail}

\subsection*{1. Introduction}

자연어처리는 텍스트 데이터를 정제, 머신러닝 알고리즘이 활용할 수 있는 형태로 변형하거나, 유용한 정보를 추출하는 작업이다.

자연어처리 과업들은 다음의 어려움이 있다.

\begin{enumerate}
    \item \textbf{Out of vocabulary problem} 은 학습 데이터에 등장하지 않은 단어를 제대로 인식하지 못하는 문제로, part of speech tagging 과 같은 tokenization 과정에 영향을 준다. 그 결과 벡터화된 정보를 이용하는 모든 작업의 성능을 저하하는 결과를 야기한다.
    \item \textbf{Dearth of Data} 문제도 발생한다. Sentence generation 과 같은 분야는 unuabeled data 를 활용할 수도 있지만, 형태소 분석이나 객체명인식 문제에서는 정확한 학습 데이터가 높은 성능을 보장한다.
    \item \textbf{Noise} 역시 텍스트 데이터 분석을 어렵게 만든다. 수치형 데이터의 경우 측정이 잘못되어 오차가 생기더라도 모델 학습에 이용할 수 있으나, typo 의 경우 tokenization 과정에서 완전히 다른 단어로 인식되기도 한다. Noise canceling 을 위한 모델들이 존재하지만, 이들은 학습데이터를 필요로 하는 경우가 많아 dearth of data 문제가 발생한다.
    \item \textbf{Ambiguity} 는 자연어처리의 다양한 부분에서 발생한다. 자연어는 다른 의미를 지니지만 같은 형태를 띄는 단어들이 존재하며, 이는 서로 다른 features 가 하나의 feature 로 표현되는 결과를 야기한다. 또한 단어는 문맥에 따라 다른 의미를 지닐 수 있는데, 문맥 별로 의미가 분류된 데이터는 거의 존재하지 않는다.
\end{enumerate}

이 논문에서 다양한 자연어처리 과업 중 다음의 과업들에 대하여 위의 문제를 해결하는 방법들을 알아본다.

\begin{enumerate}
    \item \textbf{형태소 분석}은 텍스트를 머신러닝 알고리즘이 이용할 수 있도록 벡터화 시키는데 가장 필요한 작업 중 하나로, 문장에서 symbolic 한 형태소들을 인식하는 과정이다. 이 과정의 품질이 좋지 않을 경우, 이를 이용하는 모든 과업의 성능이 저하된다. 한국어 형태소 분석을 위하여 세종 말뭉치를 이용할 수 있으나, 이는 outdate 되었으며, 각 도메인마다 사용되는 어휘가 다르기 때문에 반드시 out of vocabulary \& dearth of data 문제를 겪는다.
    \item \textbf{객체명 인식}은 문장에서 특정 종류의 단어를 인식하는 과정이다. 이는 챗봇과 같은 작업의 intention classification 과업에 가장 중요한 features 를 만드는데 이용된다. 이 역시 형태소 분석과 마찬가지로 각 도메인마다 필요한 학습데이터가 다르다.
    \item \textbf{키워드 추출}은 텍스트 요약 (summarization) 을 위한 중요한 기술이다. 그러나 문서 집합에서 어떤 단어를 키워드로 선택해야 하는지에 대한 학습 데이터가 없는 경우가 많다.
\end{enumerate}

이 논문에서는 위의 과업들을 해결하기 위하여 통계적 방법에 기반한 단어 추출 기법과 word embedding 기법을 활용한 단어 추출 기법을 이용한다.

\subsection*{2. Enhancing Korean Morphological Analysis with Word Extraction}

Tokenization 은 문장은 token 으로 구분하는 작업으로, token 의 정의는 문제에 따라 다르다. 형태소 분석은 token 을 형태소로, 품사 판별은 token 을 단어로, chunking 에서는 token 을 phrase 로 정의한다. 이 중 형태소 분석은 품사 판별과 chunking 의 전처리 과정으로 이용되기도 한다. 즉 형태소 분석에서 out of vocabulary 문제가 해결된다면 다양한 tokenization 의 성능을 높일 수 있다.

Tokenization 과정에서의 out of vocabulary problem 을 우회하기 위한 방법들도 존재하지만, 이는 과업의 단위가 문서나 문장인 machine translation 과 같은 일부의 작업에서만 활용할 수 있으며, 여전히 keyword extraction 이나 topic modeling 과 같은 과업에서는 단어를 정확히 인식하는 토크나이저가 필요하다.

단어 추출 기법은 통계정보를 이용하여 주어진 문서 집합에서 새롭게 등장하는 단어들을 인식할 수 있다. 이 방법을 통하여 학습된 형태소 분석기의 형태소 사전을 보강하면 해당 도메인의 out of vocabulary problem 을 해결하여 정확한 형태소 분석의 결과를 얻을 수 있다.

한국어에서 out of vocabulary 는 명사와 어미에서 가장 많이 등장한다. 명사는 새로운 개념을 표현하기 위하여 만들어지며, 어미는 구어체의 말투에 의하여 만들어진다. 한국어 어절의 구조적 특징을 이용하여 이들을 추출하는 방법을 제안한다.

추출된 단어는 세종말뭉치와 같은 학습데이터를 이용하여 구축된 형태소 분석기에 추가되어 주어진 문서 집합을 더 정확하게 형태소로 분해한다.

\subsection*{3. Building Named Entity Recognizer from Active Learning}

객체명 인식은 문장에서 특정 종류의 단어 (사람, 장소, 시간 등)를 인식하는 작업이다. 이를 위하여 conditional random field 나 recurrent neural network 계열의 supervise learning 알고리즘이 이용된다. 이들은 정확한 학습데이터를 요구한다. 그러나 모든 종류의 applications 에 적합한 객체명 인식 학습용 데이터는 존재할 수 없다.

그러나 Word2Vec 과 같은 word embedding 의 학습 결과는 NER tasks 에 도움이 됨이 기존 연구들에서 밝혀졌다. 또한 Conditional random field 는 NER 에 충분히 좋은 성능을 보이는 것으로 알려졌는데, 이는 conditional random field 가 이용하는 potential function 이 word sequence 로부터 named entity 를 인식하는데 필요한 질 좋은 features 를 만들기 때문이다.

Named entity recognition 에 이용되는 conditional random field 의 potential function 을 word embedding 에 적용함으로써 named entity recognition 용 word embedding 을 할 수 있다. 이로부터 효율적으로 NER 용 학습데이터를 구축할 수 있으며, 이를 이용하여 NER model 을 만들 수 있다.

\subsection*{4. Keyword Extraction}

키워드는 각 도메인마다 정의가 다르기 때문에 universal method 가 존재하기 어렵다. 하지만 대체로 관련 연구들에서는 한 도메인의 문서에 자주 등장하며, 다른 도메인과 구분되는 정보를 키워드로 정의한다.

또한 문서 집합에서의 키워드 추출은 문서 집합의 주제가 homogeneous 한지 heterogeneous 한지에 따라 다르게 접근한다.

\subsubsection*{4.1. Keyword Extraction with Homogeneous Dataset}

만약 문서 집합의 도메인이 homogeneous 하다면 TextRank 와 같은 알고리즘이 이용될 수 있다. 그러나 이는 문장이 제대로된 단어로 구분되었다는 가정을 한다. 중국어의 단어 추출 기법인 WordRank 를 한국어에 적용 가능하도록 변형한 KR-WordRank 는 homogeneous 한 문서 집합에서 단어 추출과 키워드 추출을 동시에 수행할 수 있다.

\subsubsection*{4.2. Keyword Extraction with Heterogeneous Dataset}

만약 문서 집합의 도메인이 heterogeneous 하다면 전체 문서 집합을 homogeneous 한 부분 집합으로 구분하여야 한다. 이를 위하여 document clustering 이 이용될 수 있다. 많은 군집화 알고리즘이 존재하지만, 대량의 문서 군집화에는 계산 속도와 안정성 측면에서 k-means 가 가장 적합하다. k-means 를 이용하여 효율적으로 문서 군집화를 한 뒤, 각 군집을 구분하는 features 를 선택하는 방식으로 키워드를 추출하여 문서 집합을 요약할 수 있다.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{현대차 과제의 활용 방법 (가안)}

현대차 과제 논문은 time series segmentation 을 embedding 을 이용한 것으로, 자연어처리 내용과 연결하기가 어려움. 

활용 가능성을 위하여 뉴스의 time stamp 를 document id 로 이용하여 doc2vec 으로 embedding 한 뒤 이를 segmentation 함으로써, topic detection 을 수행한 적이 있음. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{논문 작업 중인 주제}

\begin{enumerate}
    \item \textbf{명사 추출기}는 영어로 제출했었으나, 주제가 저널과 맞지 않다는 reject 을 받음. 이후 적헙한 저널을 찾아보았으나 재번역후 한국어학회지에 제출하는 것이 가장 적합할 것으로 생각됨. \textbf{Enhancing Korean Morphological Analysis with Word Extraction} 과 연결
    \item \textbf{한국어 띄어쓰기 교정}은 영어 제출용으로 번역완료 하였으나, 적합한 저널을 찾지 못하여 한국어로 재번역후 한국어학회지에 제출 가능.
    \item \textbf{Word inference} 일부의 데이터셋을 이용하여 새로운 데이터셋에서의 word embedding vector 를 유추하는 작업. 실험 중 \textbf{Building Named Entity Recognizer from Active Learning} 과 연결
    \item \textbf{Word embedding for named entity recognition} \textbf{Building Named Entity Recognizer from Active Learning} 은 알고리즘이 완성되어 있으며, 성능 평가 실험 설계 중.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{알고리즘이 완성된 주제}

\begin{enumerate}
    \item \textbf{Cohesion 을 이용한 unsupervised tokenizer} 는 word extraction 을 이용하는 unsuperised tokenization 으로, sentence lassification 과 같은 데이터 분석에서 다른 종류의 unsupervised tokenizaer 인 word piece model 보다 좋은 성능을 보임. 다른 알고리즘과 비교 실험도 완료됨. \textbf{Enhancing Korean Morphological Analysis with Word Extraction} 과 연결
    
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{알고리즘 작업 중인 주제}

\begin{enumerate}
    \item \textbf{Enhancing Korean Morphological Analysis with Word Extraction} 의 morphological analyzer.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Conferences}

\begin{enumerate}
    \item “Efficient topic modeling for single topic documents with clustering and lasso regression", 신훈식, \textbf{김현중}, 조성준, 한국BI데이터마이닝학회 2017 추계학술대회.
    \item "통계 기반 한국어 명사 추출기", \textbf{김현중}, 조성준, 한국BI데이터마이닝학회 2016 추계학술대회.
    \item "노이즈 문서를 위한 통계 기반 한국어 띄어쓰기 교정기", \textbf{김현중}, 황성구, 신윤하, 조한석, 김종윤, 조성준, 한국BI데이터마이닝학회 2016 추계학술대회.
    \item Distributed Representation of Documents with Explicit Explanatory Features, 김한결, \textbf{김현중}, 조성준, 한국BI데이터마이닝학회 2015 추계학술대회.
    Embedding categorical and numerical mixed data into continuous space for measuring distance, \textbf{김현중}, 김미숙, 김한결, 조성준, 한국BI데이터마이닝학회 2015 \item 추계학술대회.
    \item Mapping words and documents into same topic space with neural encoder, \textbf{김현중}, 김한결, 조성준, 한국BI데이터마이닝학회 2015 추계학술대회.
    \item Finding topically relevant terms from learning distributed representation, \textbf{김현중}, 김한결, 조성준, 한국BI데이터마이닝학회 2015 추계학술대회.
    \item Visualization of topological structure, \textbf{김현중}, 김한결, 조성준, 한국BI데이터마이닝학회 2015 추계학술대회.
    Fast novelty detection algorithm and its use in early fault detection for manufacturing process, 고태훈, \textbf{김현중}, 강필성, 조성준, 대한산업공학회 2015 \item 춘계공동학술대회.
    \item 고속 문서 군집화를 위한 의사 단어 벡터 표현, \textbf{김현중}, 박은정, 김미숙, 김한결, 강필성, 조성준, 대한산업공학회 2015 춘계공동학술대회.
    \item 데이터마이닝 알고리즘을 위한 효율적 k-NN Graph 계산, \textbf{김현중}, 강필성, 조성준, 2014년 11월, 대한산업공학회 2014 추계학술대회.
    \item Locality Sensitive Hashing for Nearest Neighbor Problem, \textbf{김현중}, 조성준, 2014년 11월, 한국BI데이터마이닝학회 2014 추계학술대회.
    "Bridging the semantic gap in multimedia retrieval with topic extraction from user reviews search", Eunjeong Park, \textbf{Hyunjoong Kim}, Seokho Kang, \item Sungzoon Cho, Yongki Lee, Jun 2014, INFORMS Conference on the Business of Big Data, San Jose, CA, USA.
    \item MovieRank: Combining Structural and Feature information Ranking Measure, \textbf{김현중}, 허민회, 강필성, 조성준, 2013년 11월, 2013 한국BI데이터마이닝학회 추계학술대회.
    "Improving word segmentation with unlabeled data", \textbf{Hyun-joong Kim}, Sungzoon Cho, and Pilsung Kang, July 2013, The 2nd International Symposium on \item System Informatics and Engineering (ISSIE2013), Xian, China.
    \item 프로그램 리뷰 사이트와 Twitter를 통한 TV 프로그램 인기도 비교, 고태훈, 박은정, \textbf{김현중}, 강필성, 조성준, 2013년 5월, 2013 대한산업공학회·한국경영과학회 춘계공동학술대회.
    \item 비교사학습을 이용한 한국어 단어 추출, \textbf{김현중}, 조성준, 2013년 5월, 2013 대한산업공학회·한국경영과학회 춘계공동학술대회.
    \item 단어 추출과 스트링 매치를 이용한 수기 입력 텍스트의 노이즈 처리, \textbf{김현중}, 조성준, 2013년 4월, 2013 한국BI데이터마이닝학회 춘계학술대회.
    \item TV프로그램 정보 기반 자동녹화 방법론 개발, 고태훈, 박은정, \textbf{김현중}, 조성준, 정철, 윤명환, 2012년 11월, 2012 한국경영과학회 추계학술대회.
    \item "클러스터링을 이용한 수기 입력 텍스트의 노이즈 처리", \textbf{김현중}, 김동일, 정원열, 조성준, 2012년 5월, 2012 대한산업공학회·한국경영과학회 춘계공동학술대회.
    "Two-phase KNN algorithm on sub-trajectory similarity search for efficient ballistic launching point estimation", \textbf{Hyunjoong Kim}, Soojin Kim, and \item Sungzoon Cho, July 2012, 2012 Industrial Conference on Data Mining, Berlin, Germany.
    \item "2단계 부분궤적 유사도를 이용한 효율적인 탄도 궤도 및 발사지점 추정", 김수진, \textbf{김현중}, 조성준, 2012년 5월, 2012 대한산업공학회·한국경영과학회 춘계공동학술대회.
    \item "관객의 관람평 분석을 통한 영화의 특성 추출", \textbf{김현중}, 조성준, 2012년 4월, 2012 한국BI데이터마이닝학회 춘계학술대회.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Reference}
\bibliography{reference}


\end{document}