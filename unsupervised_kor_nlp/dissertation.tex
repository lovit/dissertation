% Set parameters
% set font size
\documentclass[11pt]{article}

% set line height
\renewcommand{\baselinestretch}{2}

% line number
\usepackage{lineno}

% today
\renewcommand{\today}{}

% set margin
\usepackage{geometry}
\geometry{a4paper, left=15mm, right=15mm, top=20mm, bottom=20mm}

% for using Korean
\usepackage{kotex}

% for using multi-languages
\usepackage[english]{babel}

% for urls
\usepackage{hyperref}

% for equation
\usepackage{amsmath}
\usepackage{mathtools}

% for fixing figure position
\usepackage{float}

% for citation
\usepackage{natbib}
\bibliographystyle{apa}
\setcitestyle{authoryear,open={(},close={)},citesep={;}}

% for drawing table
\usepackage{array,multirow,graphicx,rotating,booktabs}
\usepackage[table,xcdraw]{xcolor}

% for tabularx
\usepackage{tabularx}
\newcolumntype{b}{X}
\newcolumntype{s}{>{\hsize=.5\hsize}X}
\renewcommand\arraystretch{0.8} \setlength\minrowclearance{0.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{Unsupervised Korean Natural Language Processing to Solve Out-of-Vocabulary and Dearth of Data}
\author{Hyunjoong Kim}

\maketitle
\smallskip

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

자연어처리 (natural language processing) 는 사람의 언어를 컴퓨터가 이용할 수 있는 형태의 정보로 변환하고, 이를 이용하여 과업들 (tasks) 을 수행하는 분야이다.
자연어처리에서 수행하는 과업은 다양하다.
품사 판별과 형태소 분석은 텍스트를 단어열로 분해하는 전처리 과업에 해당한다.
단어의 특정 품사나 의미를 이해하는 객체명 인식과, 키워드나 핵심 문장을 이용하여 문서 집합을 요약하는 정보 추출 과업도 자연어처리에 포함된다.
또한 사용자의 질문에 대해 적절한 답변을 탐색하는 질의 응답도 자연어처리 과업에 포함된다.

자연어처리 과업의 많은 부분은 머신 러닝 기법을 이용한다.
머신 러닝은 학습 방식에 따라 세 가지로 분류할 수 있다.
지도기반 (supervised) 머신 러닝은 객체의 특징을 기술하는 입력값 (input) 과 객체의 정답인 출력값 (output) 이 쌍으로 존재할 때 이를 이용하는 방식이다.
머신 러닝 모델은 입력값으로부터 출력값을 예측하기에 유용한 정보를 학습한다.
품사 판별의 경우, 단어 - 품사 쌍으로 이뤄진 학습 데이터를 이용하여, 단어열이 입력되었을 때 이에 해당하는 품사열을 판별하는 정보를 모델이 학습한다.
이후, 새로운 단어열이 입력되면 적절한 품사열을 출력한다.
비지도기반 (unsupervised) 머신 러닝은 데이터에 입력값만 존재할 때 쓰는 방법으로, 품사 판별의 경우, 두 단어가 앞 뒤에 등장하는 단어들의 분포가 비슷하면 하나의 품사로 이를 인식하는 Brown clustering \citep{brown1992class}) 방법이 이에 해당한다.
강화학습 (reinforcement learning) 은 각 입력값에 대한 출력값은 주어지지 않았지만, 출력값에 대한 리워드 (reward) 를 정의할 수 있을 때 이용하는 방식이다.
출력값에 대하여 피드백을 줄 수 있는 도메인에서 이용할 수 있다.
대화 시스템에서 출력된 답변에 대한 피드백을 이용하여 답변 출력 방법을 수정하는 모델이 이에 해당한다 \citep{mo2018personalizing, singh2000reinforcement, li2016deep}. 

자연어처리의 많은 연구는 지도기반 머신러닝을 이용한다.
모델이 적용될 도메인의 입력값들을 포함하는 학습용 데이터를 구축한 뒤, 지도기반 모델을 이용하여 입력값과 출력값의 관계를 학습한다.
품사 판별의 경우, 단어 - 품사 쌍으로 이뤄진 말뭉치를 이용하여 한 단어의 앞, 뒤에 등장하는 문맥들을 고려하여 해당 단어의 품사를 추정하는 패턴을 학습한다.
품사 판별과 같은 과업은 텍스트 데이터를 벡터로 변환하는 전처리 과정에 이용되는 경우가 많기 때문에 결과값에 대한 피드백을 정의하기가 어렵기 때문에 지도기반 머신러닝 방법이 적합하다.

그러나 지도기반 머신러닝 방법을 이용하는 자연어처리 모델들은 공통적으로 다음과 같은 어려움이 있다.

\begin{enumerate}
    \item \textbf{Out of vocabulary problem} : 학습 데이터에 등장하지 않은 단어를 제대로 인식하지 못하는 문제이다.
    \item \textbf{Dearth of Data} : 과업에 적합한 학습 데이터를 마련하기 어렵다.
    \item \textbf{Noise} : 텍스트 데이터에는 노이즈가 존재한다.
\end{enumerate}

첫째, 미등록 단어 문제는 학습 데이터를 이용하는 지도기반 머신 러닝 방법에서는 필연적으로 발생하는 문제이다.
언어는 사용되는 시기와 도메인에 따라 다르기 때문에 한 종류의 학습 데이터에 모든 종류의 단어가 등장하지 않는다.
특히 품사 판별기와 같은 전처리 과업에서 자주 발생하는 문제로, 신조어와 같이 새롭게 만들어진 단어를 인식하지 못하여 문장이 잘못된 단어열로 분해된다.
이 결과를 이용하면 문장이나 문서를 잘못된 벡터로 표현되기 때문에 이후의 과업들의 성능이 저하된다.
라틴계 언어들은 단어를 띄어쓰기로 구분되며, 최근의 단어 임베딩 기법들을 이용하여 품사의 추정이 손쉽게 이뤄진다 (citep{turian2010word, mikolov2013efficient, collobert2011natural}).
하지만 단어의 경계가 띄어쓰기로 구분되지 않는 한국어, 중국어, 일본어에서는 미등록 단어를 제대로 인식하기 위해서는 추가적인 단어 사전 혹은 학습 데이터가 필요하다.

둘째, 학습 데이터가 존재하지 않거나, 이를 구축하기 어려운 경우들이 많다.
객체명 인식은 장소, 사람과 같이 단어의 의미적 클래스를 분류하는 과업이다.
지도학습 기반으로 객체명 인식 모델을 학습하려면 각 클래스가 태깅된 학습데이터가 필요하다.
하지만 객체명 인식이 필요한 도메인마다 단어 클래스가 다르기 때문에 새롭게 학습 데이터를 구축해야 한다.
영화 제목을 인식하는 객체명 인식 모델을 학습하기 위해서는 영화 제목이 태깅된 학습데이터가 필요하다.

셋째, 텍스트 데이터에는 노이즈가 존재한다.
특정 과업을 위해 태깅된 데이터를 구하기는 어렵지만, 레이블이 존재하지 않는 텍스트 데이터를 구하는 것은 어렵지 않다.
많은 양의 텍스트 데이터는 사람에 의하여 제작되기 떄문에 띄어쓰기 오류나 철자법 오류가 존재한다.
사전을 이용하는 품사 판별기는 철자법이 틀린 단어를 제대로 인식할 수 없다.
또한 띄어쓰기가 제대로 지켜지지 않으면 단어 간의 경계를 제대로 인식하지 못한다.
자연어처리 과업의 성능을 높이기 위해서는 노이즈를 제거하는 과정이 필요하다.

이 논문에서는 다음의 자연어처리 과업에서 발생하는 위의 세 가지 문제를 해결하는 방법들을 제안한다.

\begin{enumerate}
    \item Korean space error correction
    \item Enhancing part of speech tagging with unsupervised word extraction
    \item Keyword extraction
\end{enumerate}

첫째, 한국어 문서의 띄어쓰기 오류를 교정한다.
한국어는 띄어쓰기 오류가 일부 포함되어도 가독이 어렵지 않기 때문에 띄어쓰기 오류가 자주 발생한다.
띄어쓰기 오류 교정은 글자 단위의 순차적 판별 (sequential labeling) 문제이기 때문에 순차적 판별 알고리즘들이 이용될 수 있다.
이들은 띄어쓰기 오류가 없는 학습 데이터로부터 글자열에 가장 적합한 띄어쓰기 품사열을 출력한다.
그러나 도메인마다 사용되는 어휘가 다르기 때문에 각 도메인에 적합한 학습 데이터를 마련해야 한다.
3 장에서 일부 띄어쓰기 오류가 포함된 학습 데이터로도 안정적인 띄어쓰기 교정을 하는 방법을 제안한다.
또한 학습 데이터의 띄어쓰기 오류 수준에 따른 교정 능력의 변화도 확인한다.

둘째, 단어 추출 기법을 이용하여 품사 판별의 성능을 높인다.
품사 판별은 미등록단어 문제를 자주 겪는다.
특히 단어의 경계가 명확히 기록되지 않는 한국어에서는 미등록단어가 작은 단위의 형태소들로 분해되는 문제가 자주 발생한다.
이를 방지하기 위하여 한국어 품사 판별기들은 사용자가 직접 사전을 추가하는 기능을 제공하지만, 사용자 사전의 구축은 사용자의 몫이다.
단어 추출 기법은 문서 집합에서 통계 기반으로 단어를 추출하는 방법이다.
4 장에서 단어 추출 기법을 품사 판별 과업 모델에 추가하여 각 도메인에 적합한 사용자 사전을 스스로 구축하는 품사 판별기를 제안한다.

셋째, 비지도학습 기반 키워드 추출 기법을 제안한다.
키워드 추출 기법은 문서 요약에 이용되는 대표적인 방법이다.
하지만 각 문서나 문서 집합에 적합한 키워드가 무엇인지 태깅된 학습 데이터는 잘 존재하지 않기 때문에 비지도학습 기반의 방법들이 제안되었다.
키워드 추출 기법은 데이터의 성질에 따라 다르게 접근해야 한다.
문서 집합이 동일한 주제에 대한 문서들로 구성되었을 경우 (homogeneous data), TextRank \citep{mihalcea2004textrank}) 같은 그래프 랭킹 기반 알고리즘이 이용될 수 있다.
하지만 TextRank 는 단어열이 제대로 분해되었을 경우 잘 작동한다.
5.1 장에서 데이터기반으로 미등록단어 문제를 해결하며 키워드를 추출하는 한국어 텍스트를 위한 그래프 갱킹 기반 방법을 제안한다.
문서 집합이 서로 다른 주제의 문서들로 구성된 경우 (heterogeneous data), 그래프 랭킹 기반 알고리즘은 빈도수가 높은 일반적인 단어들을 키워드로 선택한다.
이를 해결하기 위해서 문서 집합을 주제별로 구분하여야 한다.
5.2 장에서 문서 군집화 기법을 이용하여 문서 집합을 분류한 뒤, 각 문서 군집을 구분할 수 있는 단어를 키워드로 선택하는 방법을 제안한다.

이 논문에서 제안하는 방법들은 순차적 판별 알고리즘, 단어 임베딩 기법, 그리고 키워드 추출 알고리즘이 이용된다.
2 장에서는 이에 대하여 살펴본다.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}

\subsection{Sequential labeling}

HMM \citep{krogh1994hidden}
MEMM \citep{mccallum2000maximum}
CRF \citep{lafferty2001conditional}
CRF pos tagger \citep{toutanova2003feature}
CRF NER \citep{sang2003introduction}
CRF 그 외 semantic tagging \citep{choi2005identifying}
CRF + feature induction \citep{mccallum2003early}
semi CRF NER \citep{sarawagi2005semi}
LSTM-CRF NER \citep{lample2016neural}
LSTM + CNN CNN character feature + hidden -> output \citep{chiu2016named}
Char-RNN NER \citep{gridach2017character}
LSTM + CNN - CRF / NER, POS \citep{ma2016end}
Feed forward (from scratch format) \citep{zheng2013deep}
Feed forward POS, NER \citep{collobert2011natural}


\subsection{Word embedding}

Gaussian embedding \citep{vilnis2014word}
GloVe \citep{pennington2014glove}
PMI + SVD \citep{levy2014neural}
PMI + SVD = Word2Vec = GloVe \citep{levy2015improving}
FastText \citep{bojanowski2017enriching}
FastText supervised \citep{joulin2016bag}
CNN supervised word embedding \citep{kim2014convolutional}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Keyword extraction}

키워드 추출은 그래프 랭킹 분야와 토픽 모델링 레이블링 분야에서 주로 연구되었다.
그래프 랭킹 기반 키워드 추출 방법은 문서 집합의 주제가 단일될 때 적용 가능한 방법이며, 토픽 모델델링 레이블링은 문서 집합의 주제가 여러 가지일 때 문서 집합의 각 토픽에 대한 키워드를 추출하여 문서 집합 전체를 설명하기 위한 방법이다.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Topic labeling with keyword extraction}

토픽은 문서 집합에 존재하는 잠재적인 의미 집합으로, 부분 문서들의 집합으로 해석할 수 있다.
토픽 모델링을 위하여 다양한 방법이 제안되었다.
Latent Semantic Indexing (LSI) 은 문서 - 단어 행렬을 Singular Vector Decomposition (SVD) 를 이용하여 분해함으로써 각 문서와 단어를 토픽 공간의 벡터로 표현하였다 \citep{landauer1998introduction}.
하지만 벡터의 의미를 해석하기 어렵다는 단점이 있으며, 이를 보완하기 위하여 확률 생성 모델을 기반으로 Probablistic Latent Semantic Indexing (pLSI) 이 제안되었다 \citep{hofmann1999probabilistic}.
그러나 pLSI 는 많은 양의 패러매터를 학습해야 하는 어려움과 새로운 문서에 대한 토픽 벡터 추정 (inference) 이 어렵다는 단점이 제기되었다.
Latent Dirichlet Allocation (LDA) 은 pLSI 의 단점을 보완하는 방법으로 안정적인 학습과 새로운 문서에 대한 토픽 벡터 추정이 가능하다 \citep{blei2003latent}.
LDA 는 토픽 모델링에서 가장 많이 이용되는 방법이 되었으며, 학습 결과 단어의 생성 확률 벡터로 표현되는 토픽 벡터를 얻을 수 있다.
그러나 LDA 로부터 학습된 토픽 벡터에는 높은 확률을 가지지만 정보력이 적은 junk term 이 존재하며 \citep{newman2010evaluating}, 토픽 벡터의 크기는 모델링에 이용된 단어 개수이기 때문에 해석이 어렵다.
이러한 점을 해결하기 위하여 각 토픽을 해석할 수 있는 토픽 키워드를 추출하기 위한 다양한 방법들이 제안되었다. 

단어의 생성 확률로 표현되는 각 토픽 벡터에서 확률값이 큰 단어를 키워드로 선택하는 방법들도 제안되었지만 \citep{snyder2013topic, chuang2013topic, wallach2009evaluation}, 각 토픽이나 문서 집합에서 자주 등장하는 단어는 흔하게 등장하는 단어이지 좋은 키워드가 아니라는 주장이 제기되었다 \citep{ramage09tmsocial, newman2010evaluating, chuang2012interpretation}.
다양한 연구들은 공통적으로 다음 두 가지 조건을 만족하는 단어를 키워드로 선정한다 \citep{chuang2012termite}.

\begin{enumerate}
  \item \texttt{saliency} : 키워드가 해당 문서 집합을 대표하는가?
  \item \texttt{distinctiveness} : 한 문서 집합의 키워드를 이용하여 해당 문서 집합과 다른 문서 집합을 구분할 수 있는가?
\end{enumerate}

한 문서 집합의 키워드는 해당 문서 집합을 대표해야 하기 때문에 문서 집합 내 많은 문서에서 등장해야 한다.
하지만 한 문서 집합의 키워드는 해당 문서 집합과 다른 문서 집합을 구분할 수 있어야 한다.
이는 상반되는 기준이 될 수 있는데, 한 문서 집합에서만 등장하는 단어는 해당 문서 집합에서도 소수의 문서에서만 등장할 가능성이 높고, 다수의 문서 집합에서 등장하는 단어는 다른 문서 집합에서도 등장할 가능성이 높기 때문이다.
위의 두 기준을 모두 고려하는 방법들이 키워드 추출 방법을 제안되었다 \citep{bischof2012summarizing, newman2010evaluating, taddy2012estimation}.
한 토픽에서 유독 자주 등장하는 단어를 키워드로 선택하기 위하여 \citep{newman2010evaluating, taddy2012estimation, mimno2011optimizing} 토픽과 단어 간의 Point Mutual Information (PMI) 을 계산하여 이 값이 높은 단어를 키워드로 선택하였다.
식 \ref{eq:topic_pmi} 처럼 토픽 내 단어 생성 확률 $P(w \vert t)$ 를 문서 집합 전체의 단어 분포 $P(w)$ 로 나눔으로써 한 토픽에 유독 자주 등장하는 단어를 선정하였다.
하지만 $P(w)$ 가 매우 작은 단어는 높은 PMI 를 지니기 때문에, 토픽 내 생성 확률이 큰 몇 개의 단어를 선택한 뒤, PMI 를 계산하는 방법도 제안되었다 \citep{newman2010evaluating, alsumait2009topic}.

\begin{equation}
  \label{eq:topic_pmi}
  score(w,t) = \frac{P(w \vert t)}{P(w)}
\end{equation}

\citep{bischof2012summarizing} 도 단어의 빈도수와 토픽 간 구분력을 모두 고려하는 FREX 라는 지표를 제안하였다.
\citep{song2009topic} 은 토픽 내 단어 생성 확률과 토픽 별 생성 확률의 분산의 곱을 키워드 점수로 이용하였다.
이 방법은 한 토픽에서 자주 등장하며, 여러 토픽에서 다른 분포로 등장하는 단어를 키워드로 선택한다.
이는 문서의 클래스를 토픽으로 고려하면 문서 분류를 위한 변수 선택법들과도 비슷하다 \citep{largeron2011entropy, popescul2000automatic}.

하지만 상반되는 두 가지 기준을 동시에 고려하여 하나의 지표로 표현할 경우, 왜곡된 해석을 할 가능성이 높다 \citep{chuang2012interpretation}. 
두 가지 기준에 대한 지표를 따로 마련하고, 이들의 가중 평균 비율을 사용자가 능동적으로 조절할 수 있어야 문서 집합의 키워드를 제대로 이해할 수 있다 \citep{chuang2012interpretation}.
\citep{sievert2014ldavis}는 saliency 와 distinctiveness 를 표현하는 두 가지 지표를 계산한 뒤, 사용자가 가중 평균의 가중치를 직접 조절할 수 있는 LDAVis 라는 인터페이스를 제안하였다.
사용자는 $\lambda$ 를 조절하면서 키워드 점수를 재정의 할 수 있다.

\begin{equation}
  \label{eq:ldavis}
  score(w \vert t)_\lambda = \lambda \times \frac{P(w \vert t)}{P(w)} + (1 - \lambda) \times P(w \vert t)
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Graph ranking based keyword extraction}

그래프는 정보를 표현할 객체를 마디 (node) 로 정의하고, 객체 간의 관계를 호 (edge) 로 정의하는 표현 방식이다.
각 호는 가중치 (weight) 가 할당되며, 두 마디의 거리 혹은 유사도의 값을 가중치로 이용할 수 있다.
그래프 랭킹 방법은 그래프에서 각 마디의 중요성을 정의하는 방법으로, PageRank \citep{ilprints422}와 HITS \citep{kleinberg1999authoritative} 는 대표적인 방법이다.
PageRank 는 웹 문서 간의 하이퍼링크 구조를 이용하여 문서 간의 상대적 중요도를 계산하기 위하여 제안되었다.
이는 중요한 웹 문서로부터 링크를 (backlink) 받는 문서는 중요한 문서다는 가정에 기반한다.
하이퍼링크로 구성된 웹 문서 그래프는 방향성을 지니는 유방향 그래프이다.
한 문서의 랭크 $PR(u)$ 는 식 \ref{eq:pagerank} 처럼 문서 $u$ 로 링크를 지니는 다른 문서들의 랭크 $PR(v)$ 의 평균으로 정의된다.

\begin{equation}
  \label{eq:pagerank}
  R(u) = \sum_{v \in v \rightarrow u} \frac{PR(v)}{N_v}
\end{equation}

모든 마디가 인바운드와 아웃바운드가 존재한다면 식 \ref{eq:pagerank} 는 Markov property 를 따르기 때문에 steady state 가 존재하여 랭크의 값이 수렴한다.
랭크의 계산은 반복적 학습으로 계산될 수 있다.
모든 마디의 랭크는 마디 개수의 역수인 $\frac{1}{N}$ 으로 초기화 한다.
$k+1$ 번째 반복 단계에서의 각 마디의 랭크는 $k$ 번째 반복 단계에서의 인바운드 마디의 랭크 값의 평균으로 정의된다.

\begin{equation}
  \label{eq:pagerank_update}
  R(u)_{k+1} = \sum_{v \in v \rightarrow u} \frac{PR(v)_k}{N_v}
\end{equation}

그러나 웹 문서는 아웃바운드를 지니지 않는 문서가 존재할 수 있기 때문에 bias 를 추가한다 (식 \ref{eq:pagerank2}).
식 \ref{eq:pagerank_update} 를 따라 랭크 값을 업데이트 한 값과 초기화 값 $\frac{1}{N}$ 을 $c : 1-c$ 의 비율로 가중 평균한다.
$(1-c) \times \frac{1}{N}$ 은 모든 마디를 $1-c$ 의 비율로 랜덤하게 연결한 것과 같은 효과를 지니기 때문에 steady state 를 얻을 수 있다.

\begin{equation}
  \label{eq:pagerank2}
  PR(u) = c \times \sum_{v \in v \rightarrow u} \frac{PR(v)}{N_v} + (1-c) \times \frac{1}{N}
\end{equation}

HITS 는 각 마디가 hub 와 authority 라는 드 개의 랭크값을 할당 받으며, 랭크를 계산하는 반복 단계마다 정규화 과정이 있는 점이 다르다 (식 \ref{eq:hits}).

\begin{equation}
  \label{eq:hits}
  \begin{aligned}
  hub(u) = \sum_{v:(v \rightarrow u)} authority(v) \\
  authority(u) = \sum_{v:(v \rightarrow u)} hub(v)
  \end{aligned}
\end{equation}

식 \ref{eq:hits} 를 반복 계산할 경우, 그래프 전체의 랭크의 합이 계속 증가하기 때문에 매 반복단계마다 hub 와 authority 벡터의 크기를 일정하게 만들기 위하여 L2 정규화를 한다.
하지만 HITS 와 PageRank 는 모두 중요한 마디는 다른 중요한 마디와 연결되어 있다는 가정에 기반하기 때문에 비슷한 학습 결과를 보인다.

웹 문서 그래프에서 중요한 마디를 정의하기 위하여 제안된 그래프 랭킹 방법은 키워드 추출을 위해 사용되었다.
TextRank \citep{mihalcea2004textrank} 는 단어 그래프로부터 키워드를 추출하는 방법이다.
문장의 단어를 마디로 정의하고, 한 문장 두 단어가 연속으로 등장한 비율을 호의 가중치로 정의하면 단어 그래프를 구성할 수 있다.
단어 그래프에 PageRank 알고리즘을 적용하여 랭크가 높은 단어를 키워드로 선택한다.
한 문서의 모든 문장을 마디로, 모든 문장 간의 유사도를 호의 가중치로 정의하면 문장 그래프를 만들 수 있고, 여기에 PageRank 를 적용하여 랭크가 높은 문장을 선택함으로써 핵심 문장을 추출할 수도 있다.
단어와 문장 그래프를 구성하는 방법에 따라 다양한 변형 방법들이 제안되었다.
문장 간의 유사도를 검색 엔진의 질의어 - 문서 유사도 함수인 BM25 \citep{robertson2009probabilistic} 방법을 이용하는 방법이나 \citep{barrios2016variations}, 문장 간의 코싸인 유사도를 이용하는 LexRank \citep{erkan2004lexrank} 가 제안되었다.
이들은 모두 중요한 단어에 인접한 단어는 중요한 단어이며, 중요한 문장에 인접한 문장은 중요한 문장이라는 가정에 기반한다.

단어나 문장 그래프는 문장이 단어열로 잘 분해되었다는 가정을 한다.
하지만 미등록단어 문제가 존재하는 문서 집합에서 그래프 랭킹 기반으로 단어를 추출하기 위한 방법도 제안되었다.
WordRank \citep{chen2011simple} 는 중국어와 일본어처럼 띄어쓰기가 존재하지 않는 문서집합에서 비지도학습 기반으로 단어를 추출하기 위하여 제안된 방법이다.
WordRank 는 문장 내 모든 서브워드 (subword) 를 그래프의 마디로, 두 서브워드가 문장에서 인접한 빈도를 호의 가중치로 정의한 뒤, HITS 알고리즘을 이용하여 각 마디의 중요도를 계산한다.
단어의 경계가 제대로 나뉘어져 서브워드가 실제로 단어라면 한 서브워드 좌, 우에 단어들이 자주 인접할 것이며, 서브워드가 단어의 일부분이라면 좌, 우에 등장하는 다른 서브워드도 단어가 아니며, 이들과 연결된 다른 마디의 숫자는 적다라는 가정에 기반한다.

그러나 WordRank 는 한국어 텍스트에 적용하기가 어렵다.
비록 오류가 존재하더라도 한국어는 띄어쓰기를 기반으로 단어의 경계를 판단할 수 있으며, 문서 집합의 모든 서브워드를 키워드의 후보로 이용할 경우 조사나 어미가 높은 랭크를 받기 때문이다.
이러한 문제점을 해결하기 위하여 KR-WordRank \citep{kim2014kr} 가 제안되었다.
이는 띄어쓰기 기준으로 나뉘어진 어절의 왼쪽 부분부터 시작하는 서브워드 집합 L 과 어절의 오른쪽 부분부터 시작하는 서브워드 집합 R 로만 마디를 구성하여 PageRank 알고리즘을 적용한다.
한국어 어절 구조의 특징을 이용하여 단어가 될 수 없는 서브워드를 마디의 후보에서 제거하여 정확한 랭크가 계산되도록 하였다.
각 마디의 랭크가 계산되면 랭크가 높은 순서로 집합 L 에서만 키워드를 선택하며, 랭크가 낮은 한 단어가 집합 L 과 집합 R 의 단어들로 조합될 경우 이를 제거하는 필터링 방법을 통하여 키워드를 정제한다.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Prudent space correction and influence noise level of training data}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Enhancing part of speech tagging with unsupervised word extraction}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Keyword extraction in unsupervised manner}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Graph ranking based method for homogeneous texts}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Clustering and classification based method for heterogeneous texts}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{reference}

\end{document}
