% Set parameters
% set font size
\documentclass[11pt]{article}

% set line height
\renewcommand{\baselinestretch}{2}

% line number
\usepackage{lineno}

% today
\renewcommand{\today}{}

% set margin
\usepackage{geometry}
\geometry{a4paper, left=15mm, right=15mm, top=20mm, bottom=20mm}

% for using Korean
\usepackage{kotex}

% for using multi-languages
\usepackage[english]{babel}

% for urls
\usepackage{hyperref}

% for equation
\usepackage{amsmath}
\usepackage{mathtools}

% for fixing figure position
\usepackage{float}

% for citation
\usepackage{natbib}
\bibliographystyle{apa}
\setcitestyle{authoryear,open={(},close={)},citesep={;}}

% for drawing table
\usepackage{array,multirow,graphicx,rotating,booktabs}
\usepackage[table,xcdraw]{xcolor}

% for tabularx
\usepackage{tabularx}
\newcolumntype{b}{X}
\newcolumntype{s}{>{\hsize=.5\hsize}X}
\renewcommand\arraystretch{0.8} \setlength\minrowclearance{0.8pt}

% for itemize
\usepackage{enumitem}
\modulolinenumbers[5]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{Response to Reviews}
\author{Hyunjoong Kim}
\maketitle
\smallskip

\section{서론}
\begin{enumerate}
\item \textbf{변수 정의가 되지 않은 부분이 많다. 전반적으로 변수 정의를 명확히 하고 내용을 시작하도록 수정해야 한다.}

$i$ 번째 단어는 $w_i$, $i$ 번째 입력값은 $x_i$, $i$ 번째 출력값은 $y_i$ 로 통일한다. 단어 임베딩 벡터의 경우 임베딩 벡터임을 명시하며 $x_i$ 나 $e(w_i)$ 로 기술한다. 모든 식에 대하여 식에 이용된 변수의 의미를 설명한다.

\item \textbf{논문의 1장에서도 관련 연구에 대한 간략한 요약이 포함되어 있다. 1장과 2장을 합치는 것이 어떠한가}

2 장의 내용을 1 장의 소챕터로 변경하였다.


\item \textbf{용어 중 어떤 것은 번역이 되어 있고, 어떤 것은 번역이 되지 않았다. 이에 대한 통일이 필요하다.}

이 논문에서는 다음의 원칙으로 용어의 번역을 통일하였다. 부분단어 (subword) 처럼 머신러닝 분야에서 자주 번역되지 않은 단어는 직역하여 이용한다. "벡터", "데이터" 처럼 일반적으로 이용되는 외래어와 특정 알고리즘이 아닌 방법론, (supervised learning), 혹은 여러 해법이 존재하는 알고리즘 (logistic regression) 은 한글로 차용하여 기술한다. Word2Vec 이나 GloVe 처럼 알고리즘 고유 이름의 경우에는 번역을 하거나 한글로 차용하지 않는다. 번역이나 차용되는 단어는 매 장마다 처음 이용될 시 괄호 안에 원어를 표기한다. 

Conditional Random Field 처럼 약어가 다른 알고리즘과 혼동이 되지 않을 때에는 약어인 CRF 로 기술할 수 있으며, 약어를 이용할 때에는 매 장마다 처음 등장할 때 전체 이름을 약어와 함께 기술한다. LDA 처럼 두 가지 이상의 의미로 해석 가능한 약어의 경우에는 약어를 이용하지 않는다.

\item \textbf{LDA 처럼 두 가지의 의미를 지닐 수 있는 약어의 경우, 전체 이름을 적는 것이 오히려 명료하다.}

CRF 처럼 다른 이름과 혼동되지 않고, 한 소챕터 안에서 여러 번 연속으로 이용되는 단어에 한하여 약어를 이용하였으며, 각 장마다 처음 이용될 시 전체 이름을 약어와 함께 기술하였다. LDA 처럼 두 가지 이상의 의미로 해석될 수 있거나, 각 장에서 한 번만 이용되는 경우에는 전체 이름을 기술하였다.

\item \textbf{각 장의 이름에 어떤 것은 이름이 있고 (예: KR-WordRank), 어떤 것은 이름이 없다. 이를 통일하라.}

각 장의 이름은 제안하는 알고리즘에 의하여 해결된 문제를 기술한다. 해석이 필요한 알고리즘의 이름은 각 장의 제목이 넣지 않는다. 단 각 장마다 제안하는 모델의 이름을 정의한 뒤 사용한다.

\item \textbf{아직 문서 군집화 관련 논문이 accepted 가 아니기 때문에 안전하게 time series segmentation 논문에 기반한 챕터를 추가하라}

시계열 형식의 문서 집합을 요약하기 위하여 거리 기반으로 시간 축의 구간을 나눈 뒤, 각 구간의 대표 주제를 요약하는 방법을 챕터로 추가하였다.

\end{enumerate}


\section{관련 연구}
\begin{enumerate}
\item \textbf{Sequential labeling 은 논문에서 제안하는 방법에 이용되고 있지는 않다. 그렇기 때문에 이 부분이 관련 연구로 포함되는 것이 적절한지 재고해야 한다. 한편, 토크나이저의 분야에서는 알아야 하는 관련 연구이기 때문에 정리를 하는 것도 의미가 있다. 두 의견을 고려하여 sequential labeling 부분을 어떻게 할 것인지 판단하라.}

제안하는 방법들이 sequential labeling 을 이용하지는 않지만, 명사 추출이나 시계열 형식의 문서 구간 분리 장의 내용을 이해하기 위해서는 알아야 하는 개념이다.
또한 이후 추가 연구를 수행할 경우를 위하여 관련된 정보를 정리하는 것에도 의미가 있다고 판단하여 이를 논문에 포함하였다.

\end{enumerate}


\section{Cohesion + Unsupervised Tokenizer}
\begin{enumerate}
\item \textbf{성능 평가 1의 단어 추출 재현율에서 Cohesion 과 Cohesion + Branching Entropy 간에 성능 차이가 나는 이유에 대하여 기술}

다음의 설명을 추가하였다.
"Cohesion 만 이용하는 경우보다 Branching Entropy 와 함께 이용하는 경우 단어의 인식률이 더 높은데, 이는 배우 이름이나 캐릭터 이름과 함께 특정 조사가 자주 이용될 Cohesion 은 조사를 포함한 어절을 단어로 선택하기 때문이다.
R 의 다양성을 정량화하는 Branching Entropy 를 함께 이용할 경우 어절 내 L 과 R 의 경계가 더욱 명확하게 드러날 수 있다."

\end{enumerate}



\section{명사 추출기}
\begin{enumerate}
\item \textbf{나무위키와 네이버 한국어 사전을 이용한 뉴스 데이터에서의 명사 인식 능력의 재현율 (recall) 이 낮은 이유는 무엇인가?}

나무 위키와 네이버 한국어 사전에 등재된 명사는 뉴스에 등장한 명사 외에도 다른 도메인의 명사를 모두 포함한다.
재현율은 이 모든 단어들 중에서 명사 추출기에 의하여 인식된 단어의 비율이기 때문에 뉴스 문서에 등장하지 않은 단어에 의하여 평균적으로 낮은 재현율을 보인다. 
이에 대한 내용을 심사 발표에서는 언급하지 않았지만, 논문에서 설명하였다.

\item \textbf{발표 자료에 있는 pseudo code 가 논문에는 없다. 논문에 이 부분을 추가하라.}

제안하는 방법의 의사 코드를 (4.3.1) 장에 추가하였다.

\end{enumerate}


\section{KR-WordRank}
\begin{enumerate}
\item \textbf{Summarization 을 위한 데이터셋으로 영화평이 적합한가?}

추출 기반의 문서 요약 방법이 이용되는 경우는 뉴스와 같이 짧은 문장으로 구성되어 있고

\item \textbf{각 영화별로 수집된 영화평 데이터는 하나의 영화평이 하나의 문서로 오인될 수 있다. 여러 개의 영화평이 합쳐진 가상의 문서임을 설명할 필요가 있다.}

온라인 공간에서 영화평을 수집한 뒤, 영화별로 영화평을 모아 하나의 가상 문서를 만들었음을 설명하였다.

\item \textbf{핵심 문장이 대표성을 보이는지 확인하기 위하여 선택된 문장에 포함된 단어들이 포함된 문장의 비율을 확인할 필요가 있다}

Answer

\item \textbf{TextRank 는 오래 전에 제안된 알고리즘임에도 불구하고 해당 논문에서는 이와 성능을 비교하였다. 최근의 연구와 왜 비교하지 않았는가? 혹은 TextRank 를 이용해야 한다면 그 이유를 명시하라.}

추출 기반 핵심 문장 선택의 문제에서는 여전히 TextRank 및 문장 간 유사도 함수를 변형한 방법들이 주로 이용되고 있기 때문에 제안하는 방법과 TextRank 의 성능을 비교하였음을 논문에 추가하였다.

\end{enumerate}


\section{Clustering based keyword extraction}
\begin{enumerate}
\item \textbf{제목에서 다주제 문서 집합 요약이라 명하였는데, 이 때 기대하는 것은 요약문이다. 제목의 변경 혹은 핵심 문장 추출 과정까지 이어져 설명하는 것이 적절하다}

제목을 "다주제 문서 집합 요약을 위한 문서 군집화 알고리즘 및 군집 별 키워드 추출" 로 수정함으로써 이 장에서 제안하는 방법은 키워드 추출까지 다룸을 명시하였다.

\item \textbf{주어진 문서가 다주제인지 단일 주제인지 어떻게 판단이 가능한가? 5 장과 6 장 사이에 이에 대한 내용이 추가되어야 한다}

5장의 결론에서 "이 장의 내용은 문서 집합이 단일 주제로 구성된 상황을 가정한 것이며, 후속 연구로 주어진 문서 집합이 단일 주제로 구성되었는지를 판단하는 방법이 필요"함을 언급하였다.

\item \textbf{k-means++ 은 고차원에서 잘 작동하지 않는다고 표현하였는데, 그럼에도 제안하는 initializer 와 k-means++ 를 비교하는 것이 적절한가? 또한 k-means++ 은 Euclidean 에서 정의되는 것으로 알고 있는데, Euclidean 과 Cosine 을 비교하는 것이 적절한가?}

k-means++ 이 이용하는 거리 척도에는 제한이 없으며, 논문의 실험에서는 k-means++ 과 제안한 initializer  모두 Cosine distance 을 이용하였다.
k-means++ 이 잘 작동하지 않는다는 의미는 효율성의 측면에서 비효율적이라는 의미이며, k-means++ 도 이미 선택된 initial points 와 가까운 점을 추가 initial points 로 선택하지 않는 능력이 있다.
단지, 이를 위하여 지나치게 불필요한 계산을 많이 하고 있을 뿐이다.
논문에 이에 대한 내용이 정확히 기술되지 않았기 때문에 이 내용을 추가하였다.

\item \textbf{IMDb 의 실험에서 몇 개의 문서를 1000 개의 군집으로 군집화 하였는가? 이에 대한 내용이 기술되어야 한다}

해당 장의 실험 부분에서 데이터 별 문서와 단어의 개수가 명시되어 있다.

\end{enumerate}


\end{document}